{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3104b665-faa5-44fa-b689-8584ad0f1912",
   "metadata": {},
   "source": [
    "# Borzoi weight conversion from TensorFlow to PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1a050e-95ae-4ac4-b372-eb6588b6e78a",
   "metadata": {},
   "source": [
    "## Load packages and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "084764e4-3fef-4d05-8d99-061b51049c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da195e50-5a91-4b71-8bd5-a25bffb6389d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-17 11:58:22--  https://storage.googleapis.com/seqnn-share/borzoi/f0/model0_best.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:400c:c0b::cf, 2a00:1450:400c:c00::cf, 2a00:1450:400c:c1d::cf, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:400c:c0b::cf|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 744112468 (710M) [application/octet-stream]\n",
      "Saving to: ‘f0_model0_best.h5’\n",
      "\n",
      "f0_model0_best.h5   100%[===================>] 709.64M  25.1MB/s    in 32s     \n",
      "\n",
      "2024-04-17 11:58:55 (22.2 MB/s) - ‘f0_model0_best.h5’ saved [744112468/744112468]\n",
      "\n",
      "--2024-04-17 11:58:55--  https://storage.googleapis.com/seqnn-share/borzoi/f0/model1_best.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:400c:c0c::cf, 2a00:1450:400c:c0d::cf, 2a00:1450:400c:c06::cf, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:400c:c0c::cf|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 705639408 (673M) [application/octet-stream]\n",
      "Saving to: ‘f0_model1_best.h5’\n",
      "\n",
      "f0_model1_best.h5   100%[===================>] 672.95M  26.6MB/s    in 23s     \n",
      "\n",
      "2024-04-17 11:59:19 (29.1 MB/s) - ‘f0_model1_best.h5’ saved [705639408/705639408]\n",
      "\n",
      "--2024-04-17 11:59:19--  https://storage.googleapis.com/seqnn-share/borzoi/f1/model0_best.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:400c:c0d::cf, 2a00:1450:400c:c00::cf, 2a00:1450:400c:c06::cf, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:400c:c0d::cf|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 744112468 (710M) [application/octet-stream]\n",
      "Saving to: ‘f1_model0_best.h5’\n",
      "\n",
      "f1_model0_best.h5   100%[===================>] 709.64M  36.4MB/s    in 19s     \n",
      "\n",
      "2024-04-17 11:59:39 (36.6 MB/s) - ‘f1_model0_best.h5’ saved [744112468/744112468]\n",
      "\n",
      "--2024-04-17 11:59:39--  https://storage.googleapis.com/seqnn-share/borzoi/f1/model1_best.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:400c:c0d::cf, 2a00:1450:400c:c00::cf, 2a00:1450:400c:c06::cf, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:400c:c0d::cf|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 705639408 (673M) [application/octet-stream]\n",
      "Saving to: ‘f1_model1_best.h5’\n",
      "\n",
      "f1_model1_best.h5   100%[===================>] 672.95M  15.2MB/s    in 36s     \n",
      "\n",
      "2024-04-17 12:00:15 (18.6 MB/s) - ‘f1_model1_best.h5’ saved [705639408/705639408]\n",
      "\n",
      "--2024-04-17 12:00:15--  https://storage.googleapis.com/seqnn-share/borzoi/f2/model0_best.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:400c:c00::cf, 2a00:1450:400c:c06::cf, 2a00:1450:400c:c0d::cf, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:400c:c00::cf|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 744112468 (710M) [application/octet-stream]\n",
      "Saving to: ‘f2_model0_best.h5’\n",
      "\n",
      "f2_model0_best.h5   100%[===================>] 709.64M  36.0MB/s    in 22s     \n",
      "\n",
      "2024-04-17 12:00:37 (32.8 MB/s) - ‘f2_model0_best.h5’ saved [744112468/744112468]\n",
      "\n",
      "--2024-04-17 12:00:38--  https://storage.googleapis.com/seqnn-share/borzoi/f2/model1_best.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:400c:c0d::cf, 2a00:1450:400c:c00::cf, 2a00:1450:400c:c0c::cf, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:400c:c0d::cf|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 705639408 (673M) [application/octet-stream]\n",
      "Saving to: ‘f2_model1_best.h5’\n",
      "\n",
      "f2_model1_best.h5   100%[===================>] 672.95M  29.8MB/s    in 21s     \n",
      "\n",
      "2024-04-17 12:00:59 (31.5 MB/s) - ‘f2_model1_best.h5’ saved [705639408/705639408]\n",
      "\n",
      "--2024-04-17 12:01:00--  https://storage.googleapis.com/seqnn-share/borzoi/f3/model0_best.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:400c:c06::cf, 2a00:1450:400c:c00::cf, 2a00:1450:400c:c0c::cf, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:400c:c06::cf|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 744112468 (710M) [application/octet-stream]\n",
      "Saving to: ‘f3_model0_best.h5’\n",
      "\n",
      "f3_model0_best.h5   100%[===================>] 709.64M  43.3MB/s    in 19s     \n",
      "\n",
      "2024-04-17 12:01:19 (36.7 MB/s) - ‘f3_model0_best.h5’ saved [744112468/744112468]\n",
      "\n",
      "--2024-04-17 12:01:19--  https://storage.googleapis.com/seqnn-share/borzoi/f3/model1_best.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:400c:c00::cf, 2a00:1450:400c:c0d::cf, 2a00:1450:400c:c06::cf, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:400c:c00::cf|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 705639408 (673M) [application/octet-stream]\n",
      "Saving to: ‘f3_model1_best.h5’\n",
      "\n",
      "f3_model1_best.h5   100%[===================>] 672.95M  25.6MB/s    in 30s     \n",
      "\n",
      "2024-04-17 12:01:50 (22.2 MB/s) - ‘f3_model1_best.h5’ saved [705639408/705639408]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download weights files\n",
    "# model_0 is human, model_1 is mouse\n",
    "!wget https://storage.googleapis.com/seqnn-share/borzoi/f0/model0_best.h5 -O f0_model0_best.h5\n",
    "!wget https://storage.googleapis.com/seqnn-share/borzoi/f0/model1_best.h5 -O f0_model1_best.h5\n",
    "!wget https://storage.googleapis.com/seqnn-share/borzoi/f1/model0_best.h5 -O f1_model0_best.h5\n",
    "!wget https://storage.googleapis.com/seqnn-share/borzoi/f1/model1_best.h5 -O f1_model1_best.h5\n",
    "!wget https://storage.googleapis.com/seqnn-share/borzoi/f2/model0_best.h5 -O f2_model0_best.h5\n",
    "!wget https://storage.googleapis.com/seqnn-share/borzoi/f2/model1_best.h5 -O f2_model1_best.h5\n",
    "!wget https://storage.googleapis.com/seqnn-share/borzoi/f3/model0_best.h5 -O f3_model0_best.h5\n",
    "!wget https://storage.googleapis.com/seqnn-share/borzoi/f3/model1_best.h5 -O f3_model1_best.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797348f3-6d38-4658-96db-43a9c1851bb2",
   "metadata": {},
   "source": [
    "## Create porting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0b76f4b-73dd-4f8e-94d5-e79f4b714920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trans_lookup(n_layers):\n",
    "    def tf_count(x):\n",
    "        # TensorFlow doesn't label first layer of a kind, second is _1, third is _2, ...\n",
    "        if x == 0:\n",
    "            return \"\"\n",
    "        else:\n",
    "            return f\"_{x}\"\n",
    "    out_dict = dict()\n",
    "    for layer_i in range(n_layers):\n",
    "        out_dict[f\"layer_normalization{tf_count(2*layer_i)}\"] = f\"distal.0.{layer_i}.transf.norm\"\n",
    "        out_dict[f\"multihead_attention{tf_count(layer_i)}\"] = f\"distal.0.{layer_i}.transf.attention\"\n",
    "        out_dict[f\"layer_normalization{tf_count(2*layer_i+1)}\"] = f\"distal.0.{layer_i}.ff.norm\"\n",
    "        out_dict[f\"dense{tf_count(2*layer_i)}\"] = f\"distal.0.{layer_i}.ff.l1\"\n",
    "        out_dict[f\"dense{tf_count(2*layer_i+1)}\"] = f\"distal.0.{layer_i}.ff.l2\"\n",
    "    return out_dict\n",
    "\n",
    "def transform_the_transformer(layers, n_transformer_layers = 8):\n",
    "    weights = dict()\n",
    "    trans_lookup = make_trans_lookup(n_transformer_layers)\n",
    "    for trans_tf, trans_pt in trans_lookup.items():\n",
    "        if \"layer_normalization\" in trans_tf:\n",
    "            weights[f\"{trans_pt}.weight\"] = torch.tensor(layers[trans_tf][trans_tf]['gamma:0'][...]) #layer[0]\n",
    "            weights[f\"{trans_pt}.bias\"] = torch.tensor(layers[trans_tf][trans_tf]['beta:0'][...]) #layer[1]\n",
    "        elif \"multihead_attention\" in trans_tf:\n",
    "            weights[f\"{trans_pt}.rel_content_bias\"] = torch.tensor(layers[trans_tf]['r_w_bias:0'][...]) #layer[0]\n",
    "            weights[f\"{trans_pt}.rel_pos_bias\"] = torch.tensor(layers[trans_tf]['r_r_bias:0'][...]) #layer[1]\n",
    "            weights[f\"{trans_pt}.to_q.weight\"] = torch.tensor(layers[trans_tf][trans_tf]['q_layer']['kernel:0'][...].T) #layer[2].T\n",
    "            weights[f\"{trans_pt}.to_k.weight\"] = torch.tensor(layers[trans_tf][trans_tf]['k_layer']['kernel:0'][...].T) #layer[3].T\n",
    "            weights[f\"{trans_pt}.to_v.weight\"] = torch.tensor(layers[trans_tf][trans_tf]['v_layer']['kernel:0'][...].T) #layer[4].T\n",
    "            weights[f\"{trans_pt}.to_out.weight\"] = torch.tensor(layers[trans_tf][trans_tf]['embedding_layer']['kernel:0'][...].T) #layer[5].T\n",
    "            weights[f\"{trans_pt}.to_out.bias\"] = torch.tensor(layers[trans_tf][trans_tf]['embedding_layer']['bias:0'][...]) #layer[6]\n",
    "            weights[f\"{trans_pt}.to_rel_k.weight\"] = torch.tensor(layers[trans_tf][trans_tf]['r_k_layer']['kernel:0'][...].T) #layer[7].T\n",
    "        elif \"dense\" in trans_tf:\n",
    "            weights[f\"{trans_pt}.weight\"] = torch.tensor(layers[trans_tf][trans_tf]['kernel:0'][...].T) #layer[0].T\n",
    "            weights[f\"{trans_pt}.bias\"] = torch.tensor(layers[trans_tf][trans_tf]['bias:0'][...]) #layer[1]\n",
    "    return weights\n",
    "\n",
    "def convert_the_convs(layers):\n",
    "    weights = dict()\n",
    "    conv_lookup = {\n",
    "        \"conv1d\": \"local_list.0.0\",\n",
    "        \"conv1d_1\": \"local_list.0.2.conv_layer\",\n",
    "        \"conv1d_2\": \"local_list.0.3.conv_layer\",\n",
    "        \"conv1d_3\": \"local_list.0.4.conv_layer\",\n",
    "        \"conv1d_4\": \"local_list.0.5.conv_layer\",\n",
    "        \"conv1d_5\": \"local_list.0.6.conv_layer\",\n",
    "        \"conv1d_6\": \"local_list.1.1.conv_layer\",\n",
    "        \"separable_conv1d\" : \"final_list.0.0.conv_sep.conv_layer\",\n",
    "        \"separable_conv1d_1\": \"final_list.1.0.conv_sep.conv_layer\",\n",
    "        \"dense_16\": \"final_list.0.0.conv_input.conv_layer\",\n",
    "        \"dense_17\": \"final_list.0.0.conv_horizontal.conv_layer\",\n",
    "        \"dense_18\": \"final_list.1.0.conv_input.conv_layer\",\n",
    "        \"dense_19\": \"final_list.1.0.conv_horizontal.conv_layer\",\n",
    "        \"conv1d_7\": \"final_list.2.1.conv_layer\",\n",
    "        \"dense_20\": \"head_human.0\"\n",
    "    }\n",
    "    for conv_tf, conv_pt in conv_lookup.items():\n",
    "        if 'separable' in conv_tf:\n",
    "            weights[f\"{conv_pt}.0.weight\"] = torch.tensor(layers[conv_tf][conv_tf]['depthwise_kernel:0'][...]).permute((1,2,0)) #layers[conv_tf][0].permute((1,2,0))\n",
    "            weights[f\"{conv_pt}.1.weight\"] = torch.tensor(layers[conv_tf][conv_tf]['pointwise_kernel:0'][...]).permute((2,1,0)) #layers[conv_tf][1].permute((2,1,0))\n",
    "            weights[f\"{conv_pt}.1.bias\"] = torch.tensor(layers[conv_tf][conv_tf]['bias:0'][...]) #layers[conv_tf][2]\n",
    "        else:\n",
    "            try:\n",
    "                weights[f\"{conv_pt}.weight\"] = torch.tensor(layers[conv_tf][conv_tf]['kernel:0'][...]).permute((2,1,0)) #layers[conv_tf][0].permute((2,1,0))\n",
    "            except:\n",
    "                weights[f\"{conv_pt}.weight\"] = torch.tensor(layers[conv_tf][conv_tf]['kernel:0'][...]).unsqueeze(0).permute((2,1,0)) #layers[conv_tf][0].unsqueeze(0).permute((2,1,0))\n",
    "            weights[f\"{conv_pt}.bias\"] = torch.tensor(layers[conv_tf][conv_tf]['bias:0'][...]) #layers[conv_tf][1]\n",
    "    return weights\n",
    "\n",
    "def match_the_mouse(layers):\n",
    "    weights = dict()\n",
    "    head_lookup = {\"dense_21\": \"head_mouse.0\"}\n",
    "    for conv_tf, conv_pt in head_lookup.items():\n",
    "        try:\n",
    "            weights[f\"{conv_pt}.weight\"] = torch.tensor(layers[conv_tf][conv_tf]['kernel:0'][...]).permute((2,1,0)) #layers[conv_tf][0].permute((2,1,0))\n",
    "        except:\n",
    "            weights[f\"{conv_pt}.weight\"] = torch.tensor(layers[conv_tf][conv_tf]['kernel:0'][...]).unsqueeze(0).permute((2,1,0)) #layers[conv_tf][0].unsqueeze(0).permute((2,1,0))\n",
    "        weights[f\"{conv_pt}.bias\"] = torch.tensor(layers[conv_tf][conv_tf]['bias:0'][...]) #layers[conv_tf][1]\n",
    "    return weights\n",
    "\n",
    "def normalize_the_norms(layers):\n",
    "    weights = dict()\n",
    "    norm_lookup = {\n",
    "        \"sync_batch_normalization\": \"local_list.0.2.norm\",\n",
    "        \"sync_batch_normalization_1\": \"local_list.0.3.norm\",\n",
    "        \"sync_batch_normalization_2\": \"local_list.0.4.norm\",\n",
    "        \"sync_batch_normalization_3\": \"local_list.0.5.norm\",\n",
    "        \"sync_batch_normalization_4\": \"local_list.0.6.norm\",\n",
    "        \"sync_batch_normalization_5\": \"local_list.1.1.norm\",\n",
    "        \"sync_batch_normalization_6\": \"final_list.0.0.conv_input.norm\",\n",
    "        \"sync_batch_normalization_7\": \"final_list.0.0.conv_horizontal.norm\",\n",
    "        \"sync_batch_normalization_8\": \"final_list.1.0.conv_input.norm\",\n",
    "        \"sync_batch_normalization_9\": \"final_list.1.0.conv_horizontal.norm\",\n",
    "        \"sync_batch_normalization_10\": \"final_list.2.1.norm\"\n",
    "    }\n",
    "    for norm_tf, norm_pt in norm_lookup.items():\n",
    "        weights[f\"{norm_pt}.weight\"] = torch.tensor(layers[norm_tf][norm_tf]['gamma:0'][...]) #layers[norm_tf][0]\n",
    "        weights[f\"{norm_pt}.bias\"] = torch.tensor(layers[norm_tf][norm_tf]['beta:0'][...]) #layers[norm_tf][1]\n",
    "        weights[f\"{norm_pt}.running_mean\"] = torch.tensor(layers[norm_tf][norm_tf]['moving_mean:0'][...]) #layers[norm_tf][2]\n",
    "        weights[f\"{norm_pt}.running_var\"] = torch.tensor(layers[norm_tf][norm_tf]['moving_variance:0'][...]) #layers[norm_tf][3]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7155c2a-d48b-4fed-bdff-feb481f8b68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_normalization': 'distal.0.0.transf.norm',\n",
       " 'multihead_attention': 'distal.0.0.transf.attention',\n",
       " 'layer_normalization_1': 'distal.0.0.ff.norm',\n",
       " 'dense': 'distal.0.0.ff.l1',\n",
       " 'dense_1': 'distal.0.0.ff.l2',\n",
       " 'layer_normalization_2': 'distal.0.1.transf.norm',\n",
       " 'multihead_attention_1': 'distal.0.1.transf.attention',\n",
       " 'layer_normalization_3': 'distal.0.1.ff.norm',\n",
       " 'dense_2': 'distal.0.1.ff.l1',\n",
       " 'dense_3': 'distal.0.1.ff.l2',\n",
       " 'layer_normalization_4': 'distal.0.2.transf.norm',\n",
       " 'multihead_attention_2': 'distal.0.2.transf.attention',\n",
       " 'layer_normalization_5': 'distal.0.2.ff.norm',\n",
       " 'dense_4': 'distal.0.2.ff.l1',\n",
       " 'dense_5': 'distal.0.2.ff.l2',\n",
       " 'layer_normalization_6': 'distal.0.3.transf.norm',\n",
       " 'multihead_attention_3': 'distal.0.3.transf.attention',\n",
       " 'layer_normalization_7': 'distal.0.3.ff.norm',\n",
       " 'dense_6': 'distal.0.3.ff.l1',\n",
       " 'dense_7': 'distal.0.3.ff.l2',\n",
       " 'layer_normalization_8': 'distal.0.4.transf.norm',\n",
       " 'multihead_attention_4': 'distal.0.4.transf.attention',\n",
       " 'layer_normalization_9': 'distal.0.4.ff.norm',\n",
       " 'dense_8': 'distal.0.4.ff.l1',\n",
       " 'dense_9': 'distal.0.4.ff.l2',\n",
       " 'layer_normalization_10': 'distal.0.5.transf.norm',\n",
       " 'multihead_attention_5': 'distal.0.5.transf.attention',\n",
       " 'layer_normalization_11': 'distal.0.5.ff.norm',\n",
       " 'dense_10': 'distal.0.5.ff.l1',\n",
       " 'dense_11': 'distal.0.5.ff.l2',\n",
       " 'layer_normalization_12': 'distal.0.6.transf.norm',\n",
       " 'multihead_attention_6': 'distal.0.6.transf.attention',\n",
       " 'layer_normalization_13': 'distal.0.6.ff.norm',\n",
       " 'dense_12': 'distal.0.6.ff.l1',\n",
       " 'dense_13': 'distal.0.6.ff.l2',\n",
       " 'layer_normalization_14': 'distal.0.7.transf.norm',\n",
       " 'multihead_attention_7': 'distal.0.7.transf.attention',\n",
       " 'layer_normalization_15': 'distal.0.7.ff.norm',\n",
       " 'dense_14': 'distal.0.7.ff.l1',\n",
       " 'dense_15': 'distal.0.7.ff.l2'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_trans_lookup(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e3cdc0-047a-488f-949b-777b9a47e25c",
   "metadata": {},
   "source": [
    "## Port weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab97ad2-29c0-4cee-babd-f17bb1e82c22",
   "metadata": {},
   "source": [
    "We transfer each checkpoint individually, by reading the keras weights.h5 and saving all weights to a dictionary of tensors.   \n",
    "Its keys match the model, so it works as a pytorch state_dict dictionary for `Borzoi.load_state_dict(dict)` when loaded with `torch.load('borzoi_fold_xxx.pt')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd0c265d-adae-4771-8ea5-0cd27ac9db4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select folds to port\n",
    "weights_paths = {f\"../weights/borzoi_fold_{fold}.pt\": (f\"f{fold}_model0_best.h5\", f\"f{fold}_model1_best.h5\") for fold in range(4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07af3629-977c-43dd-a7b6-565303441183",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ../weights/borzoi_fold_0.pt\n",
      "Saved to ../weights/borzoi_fold_1.pt\n",
      "Saved to ../weights/borzoi_fold_2.pt\n",
      "Saved to ../weights/borzoi_fold_3.pt\n"
     ]
    }
   ],
   "source": [
    "# Transfer them to a pytorch state dict\n",
    "for pt_path, (human_tf_path, mouse_tf_path) in weights_paths.items():\n",
    "    # Convert weights\n",
    "    with h5py.File(human_tf_path) as human_weights, h5py.File(mouse_tf_path) as mouse_weights:\n",
    "        res_convs = convert_the_convs(human_weights['model_weights'])\n",
    "        res_mouse = match_the_mouse(mouse_weights['model_weights'])\n",
    "        res_norms = normalize_the_norms(human_weights['model_weights'])\n",
    "        res_transformers = transform_the_transformer(human_weights['model_weights'])\n",
    "    # Save weights to \n",
    "    z = {**res_convs, **res_mouse, **res_norms, **res_transformers}    \n",
    "    torch.save(z, pt_path)\n",
    "    print(f\"Saved to {pt_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "borzoi_py311_pt220",
   "language": "python",
   "name": "borzoi_py311_pt220_script"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
