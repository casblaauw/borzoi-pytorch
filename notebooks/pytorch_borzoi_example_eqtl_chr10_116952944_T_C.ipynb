{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f5cddc-2bac-4c5b-8e65-73475b890058",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "import numpy as np\n",
    "import json\n",
    "from borzoi_pytorch import Borzoi\n",
    "from borzoi_pytorch.pytorch_borzoi_helpers import predict_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e8688-635e-435b-b68d-c20f3a9af874",
   "metadata": {},
   "source": [
    "#### We check if all tracks of the WT sequence of the eQTL example are predicted with the PyTorch model as with the original TensorFlow/Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00068a0e-3a1e-48fa-990f-824a2f9b49b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "folds = 4\n",
    "model_folds = []\n",
    "\n",
    "# Load params\n",
    "with open('../borzoi_pytorch/pytorch_borzoi_arch.json') as params_file:\n",
    "    params = json.load(params_file)\n",
    "# Adjust cropping size to match the Borzoi notebook's almost-full-length output\n",
    "params['final'][2][0]['target_length'] = 16352\n",
    "\n",
    "# Create models and load in weights\n",
    "for fold in range(folds):\n",
    "    borzoi = Borzoi(params)\n",
    "    missing_keys, unexpected_keys = borzoi.load_state_dict(torch.load(f\"../weights/borzoi_fold_0.pt\"), strict = False)\n",
    "    borzoi.to(device)\n",
    "    borzoi.eval()\n",
    "    model_folds.append(borzoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eda576-6ef0-4144-929c-0dd40530473b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slices = [7522, 7523, 7524, 7525, 7526, 7527, 7528, 7529, 7530, 7531, 7532,\n",
    "            7533, 7534, 7535, 7536, 7537, 7538, 7539, 7540, 7541, 7542, 7543,\n",
    "            7544, 7545, 7546, 7547, 7548, 7549, 7550, 7551, 7552, 7553, 7554,\n",
    "            7555, 7556, 7557, 7558, 7559, 7560, 7561, 7562, 7563, 7564, 7565,\n",
    "            7566, 7567, 7568, 7569, 7570, 7571, 7572, 7573, 7574, 7575, 7576,\n",
    "            7577, 7578, 7579, 7580, 7581, 7582, 7583, 7584, 7585, 7586, 7587,\n",
    "            7588, 7589, 7590, 7591, 7592, 7593, 7594, 7595, 7596, 7597, 7598,\n",
    "            7599, 7600, 7601, 7602, 7603, 7604, 7605, 7606, 7607, 7608, 7609,\n",
    "            7610] # slices from the first eQTL example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbf376f-c125-4c59-9c1c-2bd52c91f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test sequence and pre-saved test outputs\n",
    "sequence_one_hot_wt = torch.as_tensor(np.load('../wt_seq.npy')).to(device)\n",
    "wt_pred_across_folds_tf = np.load('../wt_pred_across_folds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8ecbe4-6e4b-4c7d-855d-27840f6422e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict tracks\n",
    "wt_pred_across_folds_pt = predict_tracks(model_folds, sequence_one_hot_wt, 0, slices)\n",
    "# Reshape to match saved TensorFlow Borzoi output\n",
    "wt_pred_across_folds_pt = wt_pred_across_folds_pt.transpose(0, 2, 1)[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f3f8a2-9cc8-4537-b596-afe0d182e673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wt_pred_across_folds_pt.shape, wt_pred_across_folds_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b7b850-3471-48c8-a4f4-7c6dd26f6182",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(wt_pred_across_folds_pt, wt_pred_across_folds_tf, rtol=0, atol = 0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd20b8a9-f09e-4fd6-b3fe-903c298fedd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Up to numerical precision, the Borzoi-ensemble ported to PyTorch gets the same results as TF-based Borzoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c403f23-98e4-46e0-8f3d-6992d7b164c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wt_pred_across_folds_pt.max(), wt_pred_across_folds_tf.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557f5ca-4313-41b8-9416-cd988baa525a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wt_pred_across_folds_pt.min(), wt_pred_across_folds_tf.min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "borzoi_py311_pt220 (start_kernel.sh)",
   "language": "python",
   "name": "borzoi_py311_pt220_script"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
